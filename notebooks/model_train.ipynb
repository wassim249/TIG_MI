{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbsBJE7hPMLQ"
      },
      "source": [
        "NOTE : Please run this notebook in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8GaLJBDpdXZ",
        "outputId": "69658808-8c49-4270-fa7d-694c250220e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytzJN50L70RI",
        "outputId": "4f93f485-6343-48b6-e440-b9b69ecb0f8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=57860be082f4371414bd10d83ded9a6f60afb77a4ec0a5d7b3403e0b90006119\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19867 sha256=79f603ae5ee3314406d0598eb129c50a4dc9088765f7dcde747ae02d0a2ae24a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/42/78/0c3d438d7f5730451a25f7ac6cbf4391759d22a67576ed7c2c\n",
            "Successfully built pyngrok\n"
          ]
        }
      ],
      "source": [
        "# Install wget and ngrok for downloading and tunneling\n",
        "!pip install wget\n",
        "!pip install pyngrok\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az4FVNbt0F1G"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "from subprocess import check_output\n",
        "import urllib.request\n",
        "import base64\n",
        "from os import listdir\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from subprocess import getoutput\n",
        "import random\n",
        "from slugify import slugify\n",
        "from huggingface_hub import HfApi, CommitOperationAdd\n",
        "from huggingface_hub import create_repo\n",
        "from IPython.display import display_markdown\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h985s3ozPMLV"
      },
      "source": [
        "# Download dependencies and packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyvcqeiL65Tj",
        "outputId": "39c969cc-49d4-4c92-c374-faa523d3e0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "Done, proceed\n"
          ]
        }
      ],
      "source": [
        "# Print a message indicating that the installation process has started\n",
        "print('Installing dependencies...')\n",
        "\n",
        "\n",
        "# Change the current working directory to /content/\n",
        "%cd /content/\n",
        "# Install the accelerate package version 0.12.0 using pip, without installing its dependencies or printing any output to the console\n",
        "!pip install -qq --no-deps accelerate==0.12.0\n",
        "# Download a list of package dependencies from a URL and save it to a file\n",
        "!wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/dbdeps.txt\n",
        "# Install any .deb packages that are in the current directory\n",
        "!dpkg -i *.deb\n",
        "# Extract a compressed archive file to the root directory (/) of the system\n",
        "!tar -C / --zstd -xf gcolabdeps.tar.zst\n",
        "# Remove any .deb, .zst, and .txt files that are in the current directory\n",
        "!rm *.deb | rm *.zst | rm *.txt\n",
        "# Clone a Git repository from a URL to the current directory, with the main branch as the default branch and only one commit depth\n",
        "!git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n",
        "# Install the gradio package version 3.16.2 using pip, without installing its dependencies or printing any output to the console\n",
        "!pip install gradio==3.16.2 --no-deps -qq\n",
        "# Set an environment variable LD_PRELOAD to libtcmalloc.so\n",
        "%env LD_PRELOAD=libtcmalloc.so\n",
        "# Set an environment variable TF_CPP_MIN_LOG_LEVEL to 3\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "# Set an environment variable PYTHONWARNINGS to ignore\n",
        "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "\n",
        "# Print a message indicating that the installation process is complete and the program can proceed\n",
        "print('Done, proceed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3SsbIlxw66N"
      },
      "source": [
        "# Download the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3KHGKqyeJp9",
        "outputId": "6f7148be-a53d-412e-b689-fbc6b95edf0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1;32mDONE !\n"
          ]
        }
      ],
      "source": [
        "# Download the model\n",
        "Model_Version = \"V2.1-768px\"\n",
        "Path_to_HuggingFace= \"stabilityai/stable-diffusion-2-1\"\n",
        "MODEL_PATH = \"\"\n",
        "MODEL_LINK = \"\"\n",
        "safetensors = False\n",
        "sftnsr=\"\"\n",
        "authe=\"https://\"\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "\n",
        "if not safetensors:\n",
        "  modelnm=\"model.ckpt\"\n",
        "else:\n",
        "  modelnm=\"model.safetensors\"\n",
        "  sftnsr=\"--from_safetensors\"\n",
        "\n",
        "\n",
        "\n",
        "def downloadmodel():\n",
        "  \"\"\"\n",
        "  Download the model from HuggingFace\n",
        "  version : V1.5-512px\n",
        "  \"\"\"\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  clear_output()\n",
        "\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!vae/diffusion_pytorch_model.bin\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !wget -q -O vae/diffusion_pytorch_model.bin https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin\n",
        "    !rm -r .git\n",
        "    !rm model_index.json\n",
        "    time.sleep(1)\n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    print('DONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "         print('[1;31mSomething went wrong')\n",
        "         time.sleep(5)\n",
        "\n",
        "def newdownloadmodel():\n",
        "  \"\"\"\n",
        "  Download the model from HuggingFace\n",
        "  version : V2.1-768px\n",
        "  \"\"\"\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v2-768\n",
        "  %cd /content/stable-diffusion-v2-768\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  !rm -r /content/stable-diffusion-v2-768/.git\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  print('DONE !')\n",
        "\n",
        "\n",
        "def newdownloadmodelb():\n",
        "  \"\"\"\n",
        "  Download the model from HuggingFace\n",
        "  version : V2.1-512px\n",
        "  \"\"\"\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v2-512\n",
        "  %cd /content/stable-diffusion-v2-512\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  !rm -r /content/stable-diffusion-v2-512/.git\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  print('DONE !')\n",
        "\n",
        "\n",
        "if Path_to_HuggingFace != \"\":\n",
        "  if authe==\"https://\":\n",
        "    textenc= f\"{authe}huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n",
        "    txtenc_size=urllib.request.urlopen(textenc).info().get('Content-Length', None)\n",
        "  else:\n",
        "    textenc= f\"https://huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n",
        "    creds = base64.b64encode(f\"USER:{token}\".encode('utf-8')).decode('utf-8')\n",
        "    req=urllib.request.Request(textenc)\n",
        "    req.add_header('Authorization', f'Basic {creds}')\n",
        "    txtenc_size=urllib.request.urlopen(req).info().get('Content-Length', None)\n",
        "  if int(txtenc_size)> 670000000 :\n",
        "    if os.path.exists('/content/stable-diffusion-custom'):\n",
        "      !rm -r /content/stable-diffusion-custom\n",
        "    clear_output()\n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    print(\"V2\")\n",
        "    !mkdir /content/stable-diffusion-custom\n",
        "    %cd /content/stable-diffusion-custom\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm -r /content/stable-diffusion-custom/.git\n",
        "      %cd /content/\n",
        "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "      clear_output()\n",
        "      print('DONE !')\n",
        "    else:\n",
        "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('[1;31mCheck the link you provided')\n",
        "            time.sleep(5)\n",
        "  else:\n",
        "    if os.path.exists('/content/stable-diffusion-custom'):\n",
        "      !rm -r /content/stable-diffusion-custom\n",
        "    clear_output()\n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    print(\"V1\")\n",
        "    !mkdir /content/stable-diffusion-custom\n",
        "    %cd /content/stable-diffusion-custom\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"{authe}huggingface.co/{Path_to_HuggingFace}\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm -r /content/stable-diffusion-custom/.git\n",
        "      !rm model_index.json\n",
        "      time.sleep(1)\n",
        "      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "      %cd /content/\n",
        "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "      clear_output()\n",
        "      print('DONE !')\n",
        "    else:\n",
        "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('[1;31mCheck the link you provided')\n",
        "            time.sleep(5)\n",
        "\n",
        "elif MODEL_PATH !=\"\":\n",
        "  %cd /content\n",
        "  clear_output()\n",
        "  if os.path.exists(str(MODEL_PATH)):\n",
        "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
        "    print('[1;33mDetecting model version...')\n",
        "    Custom_Model_Version=check_output('python det.py '+sftnsr+' --MODEL_PATH '+MODEL_PATH, shell=True).decode('utf-8').replace('\\n', '')\n",
        "    clear_output()\n",
        "    print(Custom_Model_Version+' Detected')\n",
        "    !rm det.py\n",
        "    if Custom_Model_Version=='1.5':\n",
        "      !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "      !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $MODEL_PATH --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n",
        "      !rm /content/config.yaml\n",
        "\n",
        "    elif Custom_Model_Version=='V2.1-512px':\n",
        "      !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "      !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n",
        "      !rm /content/convertodiff.py\n",
        "\n",
        "    elif Custom_Model_Version=='V2.1-768px':\n",
        "      !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "      !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n",
        "      !rm /content/convertodiff.py\n",
        "\n",
        "\n",
        "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "      clear_output()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "      print('DONE !')\n",
        "    else:\n",
        "      !rm -r /content/stable-diffusion-custom\n",
        "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "        print('Conversion error')\n",
        "        time.sleep(5)\n",
        "  else:\n",
        "    while not os.path.exists(str(MODEL_PATH)):\n",
        "       print('Wrong path, use the colab file explorer to copy the path')\n",
        "       time.sleep(5)\n",
        "\n",
        "elif MODEL_LINK !=\"\":\n",
        "    %cd /content\n",
        "    clear_output()\n",
        "    !gdown --fuzzy -O $modelnm \"$MODEL_LINK\"\n",
        "    clear_output()\n",
        "    if os.path.exists(modelnm):\n",
        "      if os.path.getsize(modelnm) > 1810671599:\n",
        "        wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
        "        print('Detecting model version...')\n",
        "        Custom_Model_Version=check_output('python det.py '+sftnsr+' --MODEL_PATH '+modelnm, shell=True).decode('utf-8').replace('\\n', '')\n",
        "        clear_output()\n",
        "        print(Custom_Model_Version+' Detected')\n",
        "        !rm det.py\n",
        "        if Custom_Model_Version=='1.5':\n",
        "          !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "          !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $modelnm --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n",
        "          !rm config.yaml\n",
        "\n",
        "        elif Custom_Model_Version=='V2.1-512px':\n",
        "          !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "          !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n",
        "          !rm convertodiff.py\n",
        "\n",
        "        elif Custom_Model_Version=='V2.1-768px':\n",
        "          !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "          !python /content/convertodiff.py $modelnm /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n",
        "          !rm convertodiff.py\n",
        "\n",
        "\n",
        "        if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "          clear_output()\n",
        "          MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
        "          print('DONE !')\n",
        "        else:\n",
        "          !rm -r stable-diffusion-custom\n",
        "          !rm $modelnm\n",
        "          while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
        "            print('Conversion error')\n",
        "            time.sleep(5)\n",
        "      else:\n",
        "        while os.path.getsize(modelnm) < 1810671599:\n",
        "           print('Wrong link, check that the link is valid')\n",
        "           time.sleep(5)\n",
        "\n",
        "else:\n",
        "  if Model_Version==\"1.5\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "      downloadmodel()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "      print(\"The v1.5 model already exists, using this model.\")\n",
        "  elif Model_Version==\"V2.1-512px\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v2-512'):\n",
        "      newdownloadmodelb()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
        "      print(\"The v2-512px model already exists, using this model.\")\n",
        "  elif Model_Version==\"V2.1-768px\":\n",
        "    if not os.path.exists('/content/stable-diffusion-v2-768'):\n",
        "      newdownloadmodel()\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
        "    else:\n",
        "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
        "      print(\"The v2-768px model already exists, using this model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Setting up Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1B299g-_VJo",
        "outputId": "20dc2dd4-c2c9-469f-b915-768b22a994f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating session...\n",
            "Session created, proceed to uploading instance images\n"
          ]
        }
      ],
      "source": [
        "# Declaring important variables\n",
        "PT=\"\"\n",
        "Session_Name = \"TIG-MI SESSION\"\n",
        "Session_Link_optional = \"\"\n",
        "WORKSPACE='/content/gdrive/MyDrive/TIG-MI'\n",
        "\n",
        "# Checking if model name exists\n",
        "try:\n",
        "  MODEL_NAME\n",
        "  pass\n",
        "except:\n",
        "  MODEL_NAME=\"\"\n",
        "\n",
        "\n",
        "# checking if session name exists\n",
        "while Session_Name==\"\":\n",
        "  print('Input the Session Name:')\n",
        "  Session_Name=input('')\n",
        "Session_Name=Session_Name.replace(\" \",\"_\")\n",
        "\n",
        "# downloading session if link is provided\n",
        "if Session_Link_optional !=\"\":\n",
        "  print('Downloading session...')\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd /content\n",
        "    if not os.path.exists(str(WORKSPACE+'/Sessions')):\n",
        "      %mkdir -p $WORKSPACE'/Sessions'\n",
        "      time.sleep(1)\n",
        "    %cd $WORKSPACE'/Sessions'\n",
        "    !gdown --folder --remaining-ok -O $Session_Name  $Session_Link_optional\n",
        "    %cd $Session_Name\n",
        "    !rm -r instance_images\n",
        "    !unzip instance_images.zip\n",
        "    !rm -r concept_images\n",
        "    !unzip concept_images.zip\n",
        "    !rm -r captions\n",
        "    !unzip captions.zip\n",
        "    %cd /content\n",
        "\n",
        "# getting instance and concept images if they exist\n",
        "INSTANCE_NAME=Session_Name\n",
        "OUTPUT_DIR=\"/content/models/\"+Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
        "CONCEPT_DIR=SESSION_DIR+'/concept_images'\n",
        "CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
        "MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
        "\n",
        "# loading model from session files\n",
        "if os.path.exists(str(SESSION_DIR)):\n",
        "  mdls=[ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]\n",
        "  if not os.path.exists(MDLPTH) and '.ckpt' in str(mdls):\n",
        "\n",
        "    def f(n):\n",
        "      k=0\n",
        "      for i in mdls:\n",
        "        if k==n:\n",
        "          !mv \"$SESSION_DIR/$i\" $MDLPTH\n",
        "        k=k+1\n",
        "\n",
        "    k=0\n",
        "    print('No final checkpoint model found, select which intermediary checkpoint to use, enter only the number, (000 to skip):\\n')\n",
        "\n",
        "    for i in mdls:\n",
        "      print(str(k)+'- '+i)\n",
        "      k=k+1\n",
        "    n=input()\n",
        "    while int(n)>k-1:\n",
        "      n=input()\n",
        "    if n!=\"000\":\n",
        "      f(int(n))\n",
        "      print('Using the model '+ mdls[int(n)]+\" ...\")\n",
        "      time.sleep(2)\n",
        "    else:\n",
        "      print('Skipping the intermediary checkpoints.')\n",
        "    del n\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content\n",
        "  resume=False\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
        "  print('Loading session with no previous model, using the original model or the custom downloaded model')\n",
        "  if MODEL_NAME==\"\":\n",
        "    print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "  else:\n",
        "    print('Session Loaded, proceed to uploading instance images')\n",
        "\n",
        "# loading session with a model and checking the model version\n",
        "elif os.path.exists(MDLPTH):\n",
        "  print('Session found, loading the trained model ...')\n",
        "  wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
        "  print('Detecting model version...')\n",
        "  Model_Version=check_output('python det.py --MODEL_PATH '+MDLPTH, shell=True).decode('utf-8').replace('\\n', '')\n",
        "  clear_output()\n",
        "  print(Model_Version+' Detected')\n",
        "  !rm det.py\n",
        "  if Model_Version=='1.5':\n",
        "    !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
        "    print('Session found, loading the trained model ...')\n",
        "    !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $MDLPTH --dump_path \"$OUTPUT_DIR\" --original_config_file config.yaml\n",
        "    !rm /content/config.yaml\n",
        "\n",
        "  elif Model_Version=='V2.1-512px':\n",
        "    !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
        "    print('Session found, loading the trained model ...')\n",
        "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1-base\n",
        "    !rm /content/convertodiff.py\n",
        "\n",
        "  elif Model_Version=='V2.1-768px':\n",
        "    !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
        "    print('Session found, loading the trained model ...')\n",
        "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1\n",
        "    !rm /content/convertodiff.py\n",
        "\n",
        "\n",
        "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    resume=True\n",
        "    clear_output()\n",
        "    print('Session loaded.')\n",
        "  else:\n",
        "    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('Conversion error, if the error persists, remove the CKPT file from the current session folder')\n",
        "\n",
        "elif not os.path.exists(str(SESSION_DIR)):\n",
        "    %mkdir -p \"$INSTANCE_DIR\"\n",
        "    print('Creating session...')\n",
        "    if MODEL_NAME==\"\":\n",
        "      print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "    else:\n",
        "      print('Session created, proceed to uploading instance images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC4ukG60fgMy",
        "outputId": "e49fd949-a815-48a3-d02d-a2ad6a771d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done, proceed to the next cell\n"
          ]
        }
      ],
      "source": [
        "Remove_existing_instance_images= True # if you want to remove the existing instance images, set this to True\n",
        "IMAGES_FOLDER_OPTIONAL=\"/content/drive/MyDrive/tigmi_instance/\" # if you want to use a folder from your drive, set this to the path of the folder\n",
        "Smart_Crop_images= False # if you want to use smart crop, set this to True (it will take longer to upload the images)\n",
        "Crop_size = 512 # it can be a value from [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content\n",
        "  if not os.path.exists(\"/content/smart_crop.py\"):\n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/smart_crop.py')\n",
        "  from smart_crop import *\n",
        "\n",
        "\n",
        "# removing existing instance images and captions\n",
        "if Remove_existing_instance_images:\n",
        "  if os.path.exists(str(INSTANCE_DIR)):\n",
        "    !rm -r \"$INSTANCE_DIR\"\n",
        "  if os.path.exists(str(CAPTIONS_DIR)):\n",
        "    !rm -r \"$CAPTIONS_DIR\"\n",
        "\n",
        "if not os.path.exists(str(INSTANCE_DIR)):\n",
        "  %mkdir -p \"$INSTANCE_DIR\"\n",
        "if not os.path.exists(str(CAPTIONS_DIR)):\n",
        "  %mkdir -p \"$CAPTIONS_DIR\"\n",
        "\n",
        "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "# checking if the images folder exists\n",
        "while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
        "  print('The image folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "  IMAGES_FOLDER_OPTIONAL=input('')\n",
        "\n",
        "if IMAGES_FOLDER_OPTIONAL!=\"\":\n",
        "  if os.path.exists(IMAGES_FOLDER_OPTIONAL+\"/.ipynb_checkpoints\"):\n",
        "    %rm -r \"$IMAGES_FOLDER_OPTIONAL\"\"/.ipynb_checkpoints\"\n",
        "\n",
        "  with capture.capture_output() as cap:\n",
        "    !mv $IMAGES_FOLDER_OPTIONAL/*.txt $CAPTIONS_DIR\n",
        "\n",
        "    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      %cp -r \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n",
        "\n",
        "  print('Done, proceed to the next cell')\n",
        "\n",
        "# uploading instance images\n",
        "elif IMAGES_FOLDER_OPTIONAL ==\"\":\n",
        "  up=\"\"\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    if filename.split(\".\")[-1]==\"txt\":\n",
        "      shutil.move(filename, CAPTIONS_DIR)\n",
        "    up=[filename for filename in uploaded.keys() if filename.split(\".\")[-1]!=\"txt\"]\n",
        "  if Smart_Crop_images:\n",
        "    for filename in tqdm(up, bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      extension = filename.split(\".\")[-1]\n",
        "      identifier=filename.split(\".\")[0]\n",
        "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
        "      file = Image.open(new_path_with_file)\n",
        "      width, height = file.size\n",
        "      if file.size !=(Crop_size, Crop_size):\n",
        "        # if the image is not square, it will be cropped to a square\n",
        "        image=crop_image(file, Crop_size)\n",
        "        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n",
        "            image[0] = image[0].convert(\"RGB\")\n",
        "            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n",
        "        else:\n",
        "            image[0].save(new_path_with_file, format=extension.upper())\n",
        "      clear_output()\n",
        "  else:\n",
        "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      clear_output()\n",
        "  print('Done, proceed to the next cell')\n",
        "\n",
        "# renaming files\n",
        "with capture.capture_output() as cap:\n",
        "  %cd \"$INSTANCE_DIR\"\n",
        "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "  %cd \"$CAPTIONS_DIR\"\n",
        "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
        "\n",
        "  %cd $SESSION_DIR\n",
        "  !rm instance_images.zip captions.zip\n",
        "  !zip -r instance_images instance_images\n",
        "  !zip -r captions captions\n",
        "  %cd /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rZVzUjYskAal",
        "outputId": "4a5ebb37-c10a-4391-9e3d-56b70ef1826d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmQYfZilzY6"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OazfcRBwtq81"
      },
      "outputs": [],
      "source": [
        "Resume_Training = False # if you want to resume training, set this to True\n",
        "UNet_Training_Steps=150 # the number of training steps for the UNet [\"150\", \"200\", \"250\", \"300\", \"350\", \"400\", \"450\", \"500\", \"550\", \"600\"]\n",
        "UNet_Learning_Rate = 2e-6 # the learning rate for the UNet [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"]\n",
        "Text_Encoder_Training_Steps=3000 # the number of training steps for the Text Encoder [\"3000\", \"4000\", \"5000\", \"6000\", \"7000\", \"8000\", \"9000\", \"10000\"]\n",
        "Text_Encoder_Learning_Rate = 1e-6 # the learning rate for the Text Encoder [\"1e-6\", \"8e-7\", \"6e-7\", \"5e-7\", \"4e-7\", \"3e-7\", \"2e-7\", \"1e-7\"]\n",
        "Text_Encoder_Concept_Training_Steps=1e-6 # the learning rate for the Text Encoder [\"1e-6\", \"8e-7\", \"6e-7\", \"5e-7\", \"4e-7\", \"3e-7\", \"2e-7\", \"1e-7\"]\n",
        "Offset_Noise = True # if you want to use offset noise, set this to True\n",
        "Save_Checkpoint_Every_n_Steps = True # if you want to save checkpoints every n steps, set this to True\n",
        "Save_Checkpoint_Every=10 # the number of steps between checkpoints\n",
        "Resolution = \"512\" # the resolution of the model [\"512\", \"1024\", \"256\"]\n",
        "Start_saving_from_the_step=10 # the step from which the checkpoints will be saved\n",
        "Disconnect_after_training=False # if you want to disconnect after training, set this to True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-9QbkfAVYYU",
        "outputId": "a6bc0e5a-4ae1-47d1-d739-9f70db29b953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE, the CKPT model is in your Gdrive in the sessions folder\n"
          ]
        }
      ],
      "source": [
        "# checking if instance checkpoint exists\n",
        "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "# checking if captions checkpoint exists\n",
        "if os.path.exists(CONCEPT_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $CONCEPT_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "# checking if captions checkpoint exists\n",
        "if os.path.exists(CAPTIONS_DIR+\"/.ipynb_checkpoints\"):\n",
        "  %rm -r $CAPTIONS_DIR\"/.ipynb_checkpoints\"\n",
        "\n",
        "\n",
        "# Resume training\n",
        "if resume and not Resume_Training:\n",
        "  print('Overwrite your previously trained model ? answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?[0m')\n",
        "  while True:\n",
        "    ansres=input('')\n",
        "    if ansres=='no':\n",
        "      Resume_Training = True\n",
        "      break\n",
        "    elif ansres=='yes':\n",
        "      Resume_Training = False\n",
        "      resume= False\n",
        "      break\n",
        "\n",
        "while not Resume_Training and MODEL_NAME==\"\":\n",
        "  print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "  time.sleep(5)\n",
        "\n",
        "MODELT_NAME=MODEL_NAME # the name of the model to train\n",
        "untlr=UNet_Learning_Rate # UNet_Learning_Rate\n",
        "txlr=Text_Encoder_Learning_Rate # Text_Encoder_Learning_Rate\n",
        "trnonltxt=\"\" # train only text encoder\n",
        "\n",
        "if UNet_Training_Steps==0:\n",
        "   trnonltxt=\"--train_only_text_encoder\"\n",
        "\n",
        "Seed='' # the seed for the training\n",
        "\n",
        "ofstnse=\"\" # offset noise\n",
        "\n",
        "\n",
        "if Offset_Noise:\n",
        "  ofstnse=\"--offset_noise\"\n",
        "\n",
        "extrnlcptn=\"\" # external caption\n",
        "\n",
        "\n",
        "Res=int(Resolution) # the resolution of the model\n",
        "\n",
        "fp16 = True # if you want to use fp16, set this to True\n",
        "\n",
        "if Seed =='' or Seed=='0':\n",
        "  Seed=random.randint(1, 999999)\n",
        "else:\n",
        "  Seed=int(Seed)\n",
        "\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "precision=prec # the precision of the model\n",
        "\n",
        "resuming=\"\" # resuming\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=OUTPUT_DIR\n",
        "  print('Resuming Training...[0m')\n",
        "  resuming=\"Yes\"\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print('Previous model not found, training a new model...[0m')\n",
        "  MODELT_NAME=MODEL_NAME\n",
        "  while MODEL_NAME==\"\":\n",
        "    print('No model found, use the \"Model Download\" cell to download a model.')\n",
        "    time.sleep(5)\n",
        "\n",
        "V2=False\n",
        "if os.path.getsize(MODELT_NAME+\"/text_encoder/pytorch_model.bin\") > 670901463:\n",
        "  V2=True\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "GCUNET=\"--gradient_checkpointing\"\n",
        "TexRes=Res\n",
        "if Res<=768:\n",
        "  GCUNET=\"\"\n",
        "\n",
        "if V2:\n",
        "  if Res>704:\n",
        "    GCUNET=\"--gradient_checkpointing\"\n",
        "  if Res>576:\n",
        "    TexRes=576\n",
        "\n",
        "if 'A100' in s :\n",
        "   GCUNET=\"\"\n",
        "   TexRes=Res\n",
        "\n",
        "\n",
        "Enable_text_encoder_training= True # if you want to train the text encoder, set this to True\n",
        "Enable_Text_Encoder_Concept_Training= True # if you want to train the text encoder, set this to True\n",
        "\n",
        "if Text_Encoder_Training_Steps==0 :\n",
        "   Enable_text_encoder_training= False\n",
        "else:\n",
        "  stptxt=Text_Encoder_Training_Steps\n",
        "\n",
        "if Text_Encoder_Concept_Training_Steps==0:\n",
        "   Enable_Text_Encoder_Concept_Training= False\n",
        "else:\n",
        "  stptxtc=Text_Encoder_Concept_Training_Steps\n",
        "\n",
        "\n",
        "if Save_Checkpoint_Every==None:\n",
        "  Save_Checkpoint_Every=1\n",
        "stp=0\n",
        "if Start_saving_from_the_step==None:\n",
        "  Start_saving_from_the_step=0\n",
        "if (Start_saving_from_the_step < 200):\n",
        "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "stpsv=Start_saving_from_the_step\n",
        "if Save_Checkpoint_Every_n_Steps:\n",
        "  stp=Save_Checkpoint_Every\n",
        "\n",
        "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "    \"\"\"\n",
        "    Dump only text encoder\n",
        "    trnonltxt: train only text encoder\n",
        "    MODELT_NAME: the name of the model to train\n",
        "    INSTANCE_DIR: the instance directory\n",
        "    OUTPUT_DIR: the output directory\n",
        "    PT: the instance prompt\n",
        "    Seed: the seed for the training\n",
        "    precision: the precision of the model\n",
        "    Training_Steps: the number of training steps\n",
        "    \"\"\"\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $trnonltxt \\\n",
        "    $extrnlcptn \\\n",
        "    $ofstnse \\\n",
        "    --image_captions_filename \\\n",
        "    --train_text_encoder \\\n",
        "    --dump_only_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$TexRes \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$txlr \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "def train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n",
        "    \"\"\"\n",
        "    Train only UNet\n",
        "    stpsv: save starting step\n",
        "    stp: save n steps\n",
        "    SESSION_DIR: the session directory\n",
        "    MODELT_NAME: the name of the model to train\n",
        "    INSTANCE_DIR: the instance directory\n",
        "    OUTPUT_DIR: the output directory\n",
        "    PT: the instance prompt\n",
        "    Seed: the seed for the training\n",
        "    Res: the resolution of the model\n",
        "    precision: the precision of the model\n",
        "    Training_Steps: the number of training steps\n",
        "    \"\"\"\n",
        "    clear_output()\n",
        "    if resuming==\"Yes\":\n",
        "      print('Resuming Training...')\n",
        "    print('Training the UNet...')\n",
        "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $extrnlcptn \\\n",
        "    $ofstnse \\\n",
        "    --image_captions_filename \\\n",
        "    --train_only_unet \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GCUNET \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=$untlr \\\n",
        "    --lr_scheduler=\"linear\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "# Train only UNet\n",
        "if Enable_text_encoder_training :\n",
        "  print('Training the text encoder...')\n",
        "  if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
        "    %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
        "  dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "\n",
        "# Train only UNet\n",
        "if Enable_Text_Encoder_Concept_Training:\n",
        "  if os.path.exists(CONCEPT_DIR):\n",
        "    if os.listdir(CONCEPT_DIR)!=[]:\n",
        "      clear_output()\n",
        "      if resuming==\"Yes\":\n",
        "        print('Resuming Training...')\n",
        "      print('Training the text encoder on the concept...')\n",
        "      dump_only_textenc(trnonltxt, MODELT_NAME, CONCEPT_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxtc)\n",
        "    else:\n",
        "      clear_output()\n",
        "      if resuming==\"Yes\":\n",
        "        print('Resuming Training...[0m')\n",
        "      print('No concept images found, skipping concept training...')\n",
        "      Text_Encoder_Concept_Training_Steps=0\n",
        "      time.sleep(8)\n",
        "  else:\n",
        "      clear_output()\n",
        "      if resuming==\"Yes\":\n",
        "        print('Resuming Training...')\n",
        "      print('No concept images found, skipping concept training...')\n",
        "      Text_Encoder_Concept_Training_Steps=0\n",
        "      time.sleep(8)\n",
        "\n",
        "if UNet_Training_Steps!=0:\n",
        "  train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n",
        "\n",
        "if UNet_Training_Steps==0 and Text_Encoder_Concept_Training_Steps==0 and Text_Encoder_Training_Steps==0 :\n",
        "  print('Nothing to do')\n",
        "else:\n",
        "  if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "    prc=\"--fp16\" if precision==\"fp16\" else \"\"\n",
        "    !python /content/diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n",
        "    clear_output()\n",
        "    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "      clear_output()\n",
        "      print(\"DONE, the CKPT model is in your Gdrive in the sessions folder\")\n",
        "      if Disconnect_after_training :\n",
        "        time.sleep(20)\n",
        "        runtime.unassign()\n",
        "    else:\n",
        "      print(\"Something went wrong\")\n",
        "  else:\n",
        "    print(\"Something went wrong\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehi1KKs-l-ZS"
      },
      "source": [
        "# Test The Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAZGngFcI8hq",
        "outputId": "5d192ee2-d879-4465-94f0-e3d268c40704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating sha256 for /content/gdrive/MyDrive/TIG-MI/Sessions/TIG-MI_SESSION/TIG-MI_SESSION.ckpt: a90d2fc6e8bda647784373770cb00e1fbc8eeb25678230010217070864a457df\n",
            "Loading weights [a90d2fc6e8] from /content/gdrive/MyDrive/TIG-MI/Sessions/TIG-MI_SESSION/TIG-MI_SESSION.ckpt\n",
            "Creating model from config: /content/gdrive/MyDrive/sd/stablediffusion/configs/stable-diffusion/v2-inference-v.yaml\n",
            "LatentDiffusion: Running in v-prediction mode\n",
            "DiffusionWrapper has 865.91 M params.\n",
            "Applying scaled dot product cross attention optimization.\n",
            "Textual inversion embeddings loaded(0): \n",
            "Model loaded in 38.0s (calculate hash: 11.6s, load weights from disk: 15.9s, find config: 5.0s, create model: 0.3s, apply weights to model: 3.0s, apply half(): 1.2s, move model to device: 1.0s).\n",
            "Running on public URL: https://a8eb3c72-debf-4a4a.gradio.live\n",
            "\u001b[32m✔ Connected\n",
            "Startup time: 58.3s (import gradio: 3.9s, import ldm: 6.3s, other imports: 4.5s, load scripts: 1.2s, load SD checkpoint: 38.0s, create ui: 0.3s, gradio launch: 3.7s, scripts app_started_callback: 0.2s).\n",
            "100% 16/16 [00:03<00:00,  4.45it/s]\n"
          ]
        }
      ],
      "source": [
        "blasphemy=base64.b64decode((\"d2VidWk=\")).decode('ascii')\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  INSTANCET=INSTANCE_NAME\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "  INSTANCET\n",
        "  path_to_trained_model=SESSION_DIR+\"/\"+INSTANCET+'.ckpt'\n",
        "except:\n",
        "  print('[1;31mIt seems that you did not perform training during this session [1;32mor you chose to use a custom path,\\nprovide the full path to the model (including the name of the model):\\n')\n",
        "  path_to_trained_model=input()\n",
        "\n",
        "# checkin if the model exists\n",
        "while not os.path.exists(path_to_trained_model):\n",
        "   print(\"[1;31mThe model doesn't exist on you Gdrive, use the file explorer to get the path : \")\n",
        "   path_to_trained_model=input()\n",
        "\n",
        "fgitclone = \"git clone --depth 1\"\n",
        "\n",
        "# checkin if the model exists\n",
        "with capture.capture_output() as cap:\n",
        "    if not os.path.exists('/content/gdrive/MyDrive'):\n",
        "      !mkdir -p /content/gdrive/MyDrive\n",
        "\n",
        "\n",
        "if not os.path.exists('/content/gdrive/MyDrive/sd/stablediffusion'):\n",
        "    !wget -q -O /content/sd_rep.tar.zst https://huggingface.co/TheLastBen/dependencies/resolve/main/sd_rep.tar.zst\n",
        "    !tar -C  /content/gdrive/MyDrive --zstd -xf /content/sd_rep.tar.zst\n",
        "    !rm /content/sd_rep.tar.zst\n",
        "    clear_output()\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd\n",
        "  !git clone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy\n",
        "  %cd stable-diffusion-$blasphemy\n",
        "  !mkdir cache\n",
        "  !sed -i 's@~/.cache@/content/gdrive/MyDrive/sd/stable-diffusion-{blasphemy}/cache@' /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\n",
        "\n",
        "  clear_output()\n",
        "  !git reset --hard\n",
        "  time.sleep(1)\n",
        "  !rm webui.sh\n",
        "  !git pull\n",
        "  !git fetch --unshallow\n",
        "  !git checkout a9eab236d7e8afa4d6205127904a385b2c43bb24\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "\n",
        "Use_localtunnel = True # use localtunnel to get a public link to your Gradio interface\n",
        "\n",
        "User = \"\" # username for your Gradio interface (optional)\n",
        "Password= \"\" # password for your Gradio interface (optional)\n",
        "\n",
        "auth=f\"--gradio-auth {User}:{Password}\"\n",
        "if User ==\"\" or Password==\"\":\n",
        "  auth=\"\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd modules\n",
        "  !wget -q -O paths.py https://github.com/TheLastBen/fast-stable-diffusion/raw/5632d2ef7fffd940976538d270854ec4faf26855/AUTOMATIC1111_files/paths.py\n",
        "  !wget -q -O extras.py https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/extras.py\n",
        "  !wget -q -O sd_models.py https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/sd_models.py\n",
        "  !wget -q -O /usr/local/lib/python3.10/dist-packages/gradio/blocks.py https://github.com/TheLastBen/fast-stable-diffusion/raw/7ff88eaa1fb4997bacd9845bd487f9a14335d625/AUTOMATIC1111_files/blocks.py\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/\n",
        "\n",
        "  !sed -i \"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda'@\" /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/modules/sd_models.py\n",
        "  !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/webui.py\n",
        "  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/modules/extras.py\n",
        "  !sed -i 's@print(\\\"No module.*@@' /content/gdrive/MyDrive/sd/stablediffusion/ldm/modules/diffusionmodules/model.py\n",
        "  !sed -i 's@\\\"quicksettings\\\": OptionInfo(.*@\"quicksettings\": OptionInfo(\"sd_model_checkpoint,  sd_vae, CLIP_stop_at_last_layers, inpainting_mask_weight, initial_noise_multiplier\", \"Quicksettings list\"),@' /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/modules/shared.py\n",
        "\n",
        "\n",
        "share='--share' # share your Gradio interface (optional)\n",
        "\n",
        "configf=\"--api --disable-safe-unpickle --enable-insecure-extension-access --no-half-vae --opt-sdp-attention --no-download-sd-model --disable-console-progressbars\" # config for your Gradio interface (optional)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "if os.path.isfile(path_to_trained_model):\n",
        "  !python /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/webui.py $share --ckpt \"$path_to_trained_model\" $auth $configf\n",
        "else:\n",
        "  !python /content/gdrive/MyDrive/sd/stable-diffusion-$blasphemy/webui.py $share --ckpt-dir \"$path_to_trained_model\" $auth $configf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6OCswBQPMLa"
      },
      "source": [
        "# Upload model to HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpEAJXqmPMLa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "Upload_sample_images = False # upload sample images to your Gradio interface (optional)\n",
        "\n",
        "concept_name = \"Moroccan interior design\" # name of your Gradio interface (optional)\n",
        "if(concept_name == \"\"):\n",
        "  concept_name = Session_Name\n",
        "concept_name=concept_name.replace(\" \",\"-\")\n",
        "\n",
        "hf_token_write = \"\" # Hugging Face write access token (optional)\n",
        "if hf_token_write ==\"\":\n",
        "  print('[1;32mYour Hugging Face write access token : ')\n",
        "  hf_token_write=input()\n",
        "\n",
        "hf_token = hf_token_write\n",
        "\n",
        "api = HfApi()\n",
        "your_username = api.whoami(token=hf_token)[\"name\"]\n",
        "\n",
        "repo_id = f\"{your_username}/{slugify(concept_name)}\"\n",
        "output_dir = f'/content/models/'+INSTANCE_NAME\n",
        "\n",
        "def bar(prg):\n",
        "    br=\"[1;33mUploading to HuggingFace : \" '[0m|'+'█' * prg + ' ' * (25-prg)+'| ' +str(prg*4)+ \"%\"\n",
        "    return br\n",
        "\n",
        "print(\"[1;32mLoading...\")\n",
        "\n",
        "NM=\"False\"\n",
        "if os.path.getsize(OUTPUT_DIR+\"/text_encoder/pytorch_model.bin\") > 670901463:\n",
        "  NM=\"True\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if NM==\"False\":\n",
        "    %cd $OUTPUT_DIR\n",
        "    !rm -r safety_checker feature_extractor .git\n",
        "    !rm model_index.json\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"feature_extractor\\nsafety_checker\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    !rm -r .git\n",
        "    %cd /content\n",
        "  else:\n",
        "    %cd $OUTPUT_DIR\n",
        "    !rm -r feature_extractor .git\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"https://USER:{hf_token}@huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"feature_extractor\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    !rm -r .git\n",
        "    %cd /content\n",
        "\n",
        "\n",
        "image_string = \"\"\n",
        "\n",
        "if os.path.exists('/content/sample_images'):\n",
        "  !rm -r /content/sample_images\n",
        "Samples=\"/content/sample_images\"\n",
        "!mkdir $Samples\n",
        "clear_output()\n",
        "\n",
        "if Upload_sample_images:\n",
        "\n",
        "  print(\"[1;32mUpload Sample images of the model\")\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    shutil.move(filename, Samples)\n",
        "  %cd $Samples\n",
        "  !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
        "  %cd /content\n",
        "  clear_output()\n",
        "\n",
        "  print(bar(1))\n",
        "\n",
        "  images_upload = os.listdir(Samples)\n",
        "  instance_prompt_list = []\n",
        "  for i, image in enumerate(images_upload):\n",
        "      image_string = f'''\n",
        "  {image_string}![{i}](https://huggingface.co/{repo_id}/resolve/main/sample_images/{image})\n",
        "      '''\n",
        "\n",
        "readme_text = f'''---\n",
        "language: en\n",
        "thumbnail: https://huggingface.co/{repo_id}/raw/main/sample_images/0.png\n",
        "tags:\n",
        "- {concept_name}\n",
        "\n",
        "{image_string}\n",
        "'''\n",
        "#Save the readme to a file\n",
        "readme_file = open(\"README.md\", \"w\")\n",
        "readme_file.write(readme_text)\n",
        "readme_file.close()\n",
        "\n",
        "operations = [\n",
        "  CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\"),\n",
        "  CommitOperationAdd(path_in_repo=f\"{Session_Name}.ckpt\",path_or_fileobj=MDLPTH)\n",
        "\n",
        "]\n",
        "create_repo(repo_id,private=True, token=hf_token)\n",
        "\n",
        "api.create_commit(\n",
        "  repo_id=repo_id,\n",
        "  operations=operations,\n",
        "  commit_message=f\"Upload the concept {concept_name} embeds and token\",\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/feature_extractor\",\n",
        "  path_in_repo=\"feature_extractor\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(4))\n",
        "\n",
        "if NM==\"False\":\n",
        "  api.upload_folder(\n",
        "    folder_path=OUTPUT_DIR+\"/safety_checker\",\n",
        "    path_in_repo=\"safety_checker\",\n",
        "    repo_id=repo_id,\n",
        "    token=hf_token\n",
        "  )\n",
        "\n",
        "clear_output()\n",
        "print(bar(8))\n",
        "\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/scheduler\",\n",
        "  path_in_repo=\"scheduler\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(9))\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/text_encoder\",\n",
        "  path_in_repo=\"text_encoder\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(12))\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/tokenizer\",\n",
        "  path_in_repo=\"tokenizer\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(13))\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/unet\",\n",
        "  path_in_repo=\"unet\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(21))\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=OUTPUT_DIR+\"/vae\",\n",
        "  path_in_repo=\"vae\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(23))\n",
        "\n",
        "api.upload_file(\n",
        "  path_or_fileobj=OUTPUT_DIR+\"/model_index.json\",\n",
        "  path_in_repo=\"model_index.json\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(24))\n",
        "\n",
        "api.upload_folder(\n",
        "  folder_path=Samples,\n",
        "  path_in_repo=\"sample_images\",\n",
        "  repo_id=repo_id,\n",
        "  token=hf_token\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "print(bar(25))\n",
        "\n",
        "display_markdown(f'''## TIG-MIT was saved successfully. [Click here to access it](https://huggingface.co/{repo_id})\n",
        "''', raw=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSuQWtuWPMLb"
      },
      "source": [
        "Thank you for reading this notebook.\n",
        "1337 ♥\n",
        "NEURALIKA TEAM\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}